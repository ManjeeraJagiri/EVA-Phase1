{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA7_S2_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kYM3ylzYo1Q"
      },
      "source": [
        "![PyTorch](https://devblogs.nvidia.com/wp-content/uploads/2017/04/pytorch-logo-dark.png)\n",
        "\n",
        "An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcVqSTrWY6oz"
      },
      "source": [
        "# Tensor - Pytorch's core data structure\n",
        "\n",
        "In Python we can create lists, lists of lists, lists of lists and so on. In NumPy there is a `numpy.ndarray` which represents `n`- dimensional array. In math there is a special name for the generalization of vectors and matrices to a higher dimensional space - a tensor\n",
        "\n",
        "Tensor is an entity with a defined number of dimensions called an order (rank). \n",
        "\n",
        "**Scalar** can be considered as a rank-0-tensor. \n",
        "\n",
        "**Vector** can be introduced as a rank-1-tensor. \n",
        "\n",
        "**Matrices** can be considered as a rank-2-tensor.\n",
        "\n",
        "# Tensor Basics\n",
        "\n",
        "Let's import the torch module first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-oFVL2tYYqp"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGxuR5IEaFJa"
      },
      "source": [
        "## Tensor Creation\n",
        "Let's view examples of matrices and tensors generation\n",
        "\n",
        "2-dimensional (rank-2) tensor of zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "897JQc25aD3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7610ea-d7a0-4a6a-c33e-fef7f54a42f8"
      },
      "source": [
        "torch.zeros(3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pujmpEBhaPRA"
      },
      "source": [
        "Random rank-3 tensor:\n",
        "_read the print below and convince yourself how this is a rank-3-tensor and learn what those 2, 3, 4 values are there for_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBrznTNhaOL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc89aaff-bd60-4f86-f29c-e89e7f053cb1"
      },
      "source": [
        "torch.rand(2, 3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.1148, 0.2543, 0.7310, 0.6567],\n",
              "         [0.4707, 0.2020, 0.5631, 0.5483],\n",
              "         [0.4714, 0.1566, 0.2033, 0.7806]],\n",
              "\n",
              "        [[0.1998, 0.8805, 0.4942, 0.8079],\n",
              "         [0.6686, 0.3216, 0.1509, 0.7184],\n",
              "         [0.0572, 0.8401, 0.6763, 0.0141]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO4fIr15asdi"
      },
      "source": [
        "I am hoping you have noticed 4-elements in a row, 3 rows making one block and there are 2 blocks. \n",
        "\n",
        "Random rank-4-tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCLvMGCaVZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d2cea9-562a-4641-877c-bd66aa49a641"
      },
      "source": [
        "torch.rand(2, 2, 2, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.8800, 0.3590, 0.7079],\n",
              "          [0.1624, 0.4920, 0.3815]],\n",
              "\n",
              "         [[0.3445, 0.6949, 0.3522],\n",
              "          [0.9417, 0.4152, 0.4956]]],\n",
              "\n",
              "\n",
              "        [[[0.5774, 0.3800, 0.1207],\n",
              "          [0.8322, 0.9045, 0.3491]],\n",
              "\n",
              "         [[0.4173, 0.5161, 0.2998],\n",
              "          [0.9009, 0.2438, 0.5980]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF6VL68s3AMV"
      },
      "source": [
        "## Question 1:\n",
        "\n",
        "How many dimensions are there in a tensor defined as below?<hr>\n",
        "4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IbXcI3x3Ibt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c0f52b-17e5-4019-a910-5bd85f3ed1ae"
      },
      "source": [
        "torch.rand(1, 1, 1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.8494]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmgpqssRa9jF"
      },
      "source": [
        ".\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "There are many more ways to create tensor using some restrictions on values it should contatn - for the full reference, please follow the [official docs](https://pytorch.org/docs/stable/torch.html#creation-ops). \n",
        "\n",
        "\n",
        ".\n",
        "---\n",
        "\n",
        "\n",
        "# Python / NumPy / Pytorch interoperability\n",
        "\n",
        "You can create tensors from python as well as numpy arrays. You can also convert torch tensors to numpy arrays. So, the interoperability between torch and numpy is pretty good. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipgpeWPfa6gE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85015b31-28df-4bfa-bb65-e48b7d258b2c"
      },
      "source": [
        "# Simple Python List\n",
        "python_list = [1, 2]\n",
        "\n",
        "# Create a numpy array from python list\n",
        "numpy_array = np.array(python_list)\n",
        "\n",
        "# Create a torch Tensor from python list\n",
        "tensor_from_list = torch.tensor(python_list)\n",
        "\n",
        "# Create a torch Tensor from Numpy array\n",
        "tensor_from_array = torch.tensor(numpy_array)\n",
        "\n",
        "# Another way to create a torch Tensor from Numpy array (share same storage)\n",
        "tensor_from_array_v2 = torch.from_numpy(numpy_array)\n",
        "\n",
        "# Convert torch tensor to numpy array\n",
        "array_from_tensor = tensor_from_array.numpy()\n",
        "\n",
        "print('List:   ', python_list)\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_list)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)\n",
        "print('Array:  ', array_from_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List:    [1, 2]\n",
            "Array:   [1 2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Array:   [1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_x-86B8gqik"
      },
      "source": [
        "**Difference between** `torch.Tensor` **and** `torch.from_numpy`\n",
        "\n",
        "Pytorch aims to be an effective library for computations. What does it mean? It means that pytorch avoids memory copying if it can. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHCKDGpygn_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c672bfb7-3dc0-49fd-afe1-62fd339b181e"
      },
      "source": [
        "numpy_array[0] = 10\n",
        "\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array:   [10  2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([10,  2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CKtdNRM3SMp"
      },
      "source": [
        "## Question 2:\n",
        "\n",
        "Assume that we moved our complete (cats vs dogs) image dataset to numpy arrays. Then we use torch.from_numpy to convert these images to tensor. Then we apply a specific data augmentation strategy called \"CutOut\" which blocks a portion of the image directly on these tensors. What will happen to the accuracy of a model trained on this strategy compared to the one without this strategy? CutOut strategy is shown below: <hr>\n",
        "Accuracy of a model trained on this strategy will be lower\n",
        "\n",
        "![CutOut](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSnSyN835AmtQPKQbPjDHX-FmshNilbtexX95cRGQPwl56QCGDn)\n",
        "\n",
        "## Question 3:\n",
        "Why do you think we are observing this behavior? <hr>\n",
        "Since the tensor shares storage with numpy arrays, the CutOut will keep happening to the original image\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZq7O-aihSOA"
      },
      "source": [
        "We have two different ways to create tensor from its NumPy counterpart - one copies memory and another one shares the same underlying storage. It works in the opposite way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFOwV8EhPwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad17012-5677-4105-ed7d-9b30d443de49"
      },
      "source": [
        "array_from_tensor = tensor_from_array.numpy()\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)\n",
        "\n",
        "tensor_from_array[0] = 11\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:  tensor([1, 2])\n",
            "Array:  [1 2]\n",
            "Tensor:  tensor([11,  2])\n",
            "Array:  [11  2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM9ytbvKhtCw"
      },
      "source": [
        "## Data types\n",
        "\n",
        "The basic data type of all Deep Learning-related operations is float, but sometimes you may need something else. Pytorch support different number types for its tensors the same way NumPy does it - by specifying the data type on tensor creation or via casting. Ths full list of supported data types can be found [here](https://pytorch.org/docs/stable/tensors.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd6WkzJ4hpYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6000b1b-184d-4f87-c758-abc5d3fa2d17"
      },
      "source": [
        "tensor = torch.zeros(2, 2)\n",
        "print('Tensor with default type: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.float16)\n",
        "print('Tensor with 16-bit float: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.int16)\n",
        "print('Tensor with integers: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.bool)\n",
        "print('Tensor with boolean data: ', tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with default type:  tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "Tensor with 16-bit float:  tensor([[0., 0.],\n",
            "        [0., 0.]], dtype=torch.float16)\n",
            "Tensor with integers:  tensor([[0, 0],\n",
            "        [0, 0]], dtype=torch.int16)\n",
            "Tensor with boolean data:  tensor([[False, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9F4Dkdr40TE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Question 4:\n",
        "We saw above that some times numpy and tensors share same storage and changing one changes the other. \n",
        "If we define a rank-2-tensor with ones (dtype of f16), and then convert it into a numpy data type using tensor.numpy() and store it in a variable called \"num\", and then we perform this operation `num = num * 0.5`, will the original tensor have 1.0s or 0.5s as its element values? <hr>\n",
        "1.0s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZtLcOg-QYQC",
        "outputId": "9be7f1b6-99ac-4890-ad84-23a318b7d554"
      },
      "source": [
        "tensor = torch.ones(2, 2, dtype=torch.float16)\n",
        "num = tensor.numpy()\n",
        "print('Tensor: ', tensor)\n",
        "print('Array: ', num)\n",
        "\n",
        "num = num * 0.5\n",
        "print('Tensor: ', tensor)\n",
        "print('Array: ', num)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:  tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n",
            "Array:  [[1. 1.]\n",
            " [1. 1.]]\n",
            "Tensor:  tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n",
            "Array:  [[0.5 0.5]\n",
            " [0.5 0.5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiQt8Mmm51OE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 5: \n",
        "If the operation `num = num*5` is changed to `num[:] = num*5` will the original tensor have 1.0s or 0.5s as its element values? <hr>\n",
        "0.5s\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ask9RUSLML",
        "outputId": "f5c6847e-6a58-49de-cbfe-430b3a8900bc"
      },
      "source": [
        "tensor = torch.ones(2, 2, dtype=torch.float16)\n",
        "num = tensor.numpy()\n",
        "print('Tensor: ', tensor)\n",
        "print('Array: ', num)\n",
        "\n",
        "num[:] = num*5\n",
        "print('Tensor: ', tensor)\n",
        "print('Array: ', num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:  tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n",
            "Array:  [[1. 1.]\n",
            " [1. 1.]]\n",
            "Tensor:  tensor([[5., 5.],\n",
            "        [5., 5.]], dtype=torch.float16)\n",
            "Array:  [[5. 5.]\n",
            " [5. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzh8UB8KiVmb"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "Tensor provides access to its elements via the same `[]` operation as a regular python list or NumPy array. However, as you may recall from NumPy usage, the full power of math libraries is accessible only via vectorized operations, i.e. operations without explicit looping over all vector elements in python and using implicit optimized loops in C/C++/CUDA/Fortran/etc. available via special function calls. Pytorch employs the same paradigm and provides a wide range of vectorized operations. Let's take a look at some examples. \n",
        "\n",
        "Joining a list of tensors together with `torch.cat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMaCDKPhiUAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bcbf585-6992-41fc-cf56-4bdfcf43e66e"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "print(torch.cat((a, b), dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bj4aeE86zdH"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 6: \n",
        "Is the transpose of concatenated a & b tensor on dimension 1, same as the contatenated tensor of a & b on dimension 0? <hr>\n",
        "No\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfIFH314TP5I",
        "outputId": "99010e5d-12c7-4c4a-ca44-8394a71c6177"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "print(torch.cat((a, b), dim=0))\n",
        "\n",
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "concat_tensor = torch.cat((a, b), dim=1)\n",
        "print (concat_tensor)\n",
        "transp_tensor = torch.transpose(concat_tensor,0,1)\n",
        "print (transp_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0., 1., 1.],\n",
            "        [0., 0., 1., 1.],\n",
            "        [0., 0., 1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TXNne69j7LP"
      },
      "source": [
        "Indexing with another tenxor/array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiE-Fsi4jVd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc2ccb8-7a40-4742-8dbf-4a10cd17173d"
      },
      "source": [
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(0, 10) > 5\n",
        "print(a)\n",
        "print(indices)\n",
        "print(a[indices])\n",
        "\n",
        "indices = torch.arange(start=0, end=10) %5\n",
        "print(indices)\n",
        "print(a[indices])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "[False False False False False False  True  True  True  True]\n",
            "tensor([6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS4dnlu47WQu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 7:\n",
        "\n",
        "`a` is defined as `torch.arange(start=0, end=10)`. We will create `b` using the two operations as below. In both cases do we get the same value?\n",
        "\n",
        "\n",
        "1.   indices variable created by the modulo operation on arange between 0 and 10. Then a new varialble `b` is created from `a` using the last 5 elements of indices. \n",
        "2.   indices variable created by the modulo operation on arange betwenn 1 and 11. Then a new varialble `b` is created from `a` using the last 5 elements of indices. <hr>\n",
        "No\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxef572OGvXS",
        "outputId": "1d7237a6-01e0-4530-efd2-1ace21d25fee"
      },
      "source": [
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(0, 10) %5\n",
        "print(a)\n",
        "print(indices)\n",
        "print(a[indices])\n",
        "\n",
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(1, 11) %5\n",
        "print(a)\n",
        "print(indices)\n",
        "print(a[indices])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "[0 1 2 3 4 0 1 2 3 4]\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "[1 2 3 4 0 1 2 3 4 0]\n",
            "tensor([1, 2, 3, 4, 0, 1, 2, 3, 4, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ4ZCVsTk-KH"
      },
      "source": [
        "What should we do if we have, say, rank-2-tensor and want to select only some rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GtRpotjkt1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ffecb7-3925-402e-8d03-d1fe19321d37"
      },
      "source": [
        "tensor = torch.rand((5, 3))\n",
        "rows = torch.tensor([0, 2])\n",
        "print(tensor)\n",
        "tensor[rows]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3337, 0.8904, 0.2443],\n",
            "        [0.9393, 0.3920, 0.5385],\n",
            "        [0.3464, 0.4526, 0.8416],\n",
            "        [0.6757, 0.1085, 0.5177],\n",
            "        [0.7293, 0.3921, 0.1802]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3337, 0.8904, 0.2443],\n",
              "        [0.3464, 0.4526, 0.8416]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIJnr_N2_Qaf"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 8: \n",
        "\n",
        "Consider a tensor defined as `torch.rand((6, 5))`. Is the shape of the new tensor created by taking the 0th, 2nd and 4th row of the old tensor same as the shape of the a newer tensor created by taking the 0th, 2nd and 4th row of the old tensor after transposing it by operation `torch.transpose(tensor, 0, 1)` ?<hr>\n",
        "No\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI1Wuk7gIW9q",
        "outputId": "bd930810-de45-45d7-e57d-ac9b0321f4c9"
      },
      "source": [
        "tensor = torch.rand((6, 5))\n",
        "rows = torch.tensor([0, 2, 4])\n",
        "print(tensor)\n",
        "print (tensor[rows])\n",
        "\n",
        "transp_tensor = torch.transpose(tensor, 0, 1)\n",
        "rows = torch.tensor([0, 2, 4])\n",
        "print(transp_tensor)\n",
        "print (transp_tensor[rows])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4872, 0.0722, 0.0516, 0.0248, 0.4629],\n",
            "        [0.1509, 0.0473, 0.2833, 0.4541, 0.0765],\n",
            "        [0.6357, 0.1323, 0.5207, 0.8740, 0.3426],\n",
            "        [0.1914, 0.7065, 0.3073, 0.5239, 0.0078],\n",
            "        [0.3066, 0.9519, 0.7203, 0.6851, 0.4519],\n",
            "        [0.9503, 0.1457, 0.5038, 0.7593, 0.6557]])\n",
            "tensor([[0.4872, 0.0722, 0.0516, 0.0248, 0.4629],\n",
            "        [0.6357, 0.1323, 0.5207, 0.8740, 0.3426],\n",
            "        [0.3066, 0.9519, 0.7203, 0.6851, 0.4519]])\n",
            "tensor([[0.4872, 0.1509, 0.6357, 0.1914, 0.3066, 0.9503],\n",
            "        [0.0722, 0.0473, 0.1323, 0.7065, 0.9519, 0.1457],\n",
            "        [0.0516, 0.2833, 0.5207, 0.3073, 0.7203, 0.5038],\n",
            "        [0.0248, 0.4541, 0.8740, 0.5239, 0.6851, 0.7593],\n",
            "        [0.4629, 0.0765, 0.3426, 0.0078, 0.4519, 0.6557]])\n",
            "tensor([[0.4872, 0.1509, 0.6357, 0.1914, 0.3066, 0.9503],\n",
            "        [0.0516, 0.2833, 0.5207, 0.3073, 0.7203, 0.5038],\n",
            "        [0.4629, 0.0765, 0.3426, 0.0078, 0.4519, 0.6557]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naDzFMkslU0b"
      },
      "source": [
        "## Tensor Shapes\n",
        "\n",
        "Reshaping a tensor is a frequently used operation. We can change the shape of a tensor without the memory copying overhead. There are two methods for that: `reshape` and `view`. \n",
        "\n",
        "The difference is the following: \n",
        "\n",
        "\n",
        "*   view tries to return a tensor, and it shares the same memory with the original tensor. In case, if it cannot reuse the same memory due to [some reason](https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view), it just fails. \n",
        "*   reshape always returns the tensor with the desired shape and tries to reuse the memory. If it cannot, it creates a copy\n",
        "\n",
        "Let's see with the help of an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HClDkqLLlMJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "703bf39f-96e5-4990-90bb-1b59b96a01fb"
      },
      "source": [
        "tensor = torch.rand(2, 3, 4)\n",
        "print('Pointer to data: ', tensor.data_ptr())\n",
        "print('Shape: ', tensor.shape)\n",
        "\n",
        "reshaped = tensor.reshape(24)\n",
        "\n",
        "view = tensor.view(3, 2, 4)\n",
        "print('Reshaped tensor - pointer to data', reshaped.data_ptr())\n",
        "print('Reshaped tensor shape ', reshaped.shape)\n",
        "\n",
        "print('Viewed tensor - pointer to data', view.data_ptr())\n",
        "print('Viewed tensor shape ', view.shape)\n",
        "\n",
        "assert tensor.data_ptr() == view.data_ptr()\n",
        "\n",
        "assert np.all(np.equal(tensor.numpy().flat, reshaped.numpy().flat))\n",
        "\n",
        "print('Original stride: ', tensor.stride())\n",
        "print('Reshaped stride: ', reshaped.stride())\n",
        "print('Viewed stride: ', view.stride())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pointer to data:  54042240\n",
            "Shape:  torch.Size([2, 3, 4])\n",
            "Reshaped tensor - pointer to data 54042240\n",
            "Reshaped tensor shape  torch.Size([24])\n",
            "Viewed tensor - pointer to data 54042240\n",
            "Viewed tensor shape  torch.Size([3, 2, 4])\n",
            "Original stride:  (12, 4, 1)\n",
            "Reshaped stride:  (1,)\n",
            "Viewed stride:  (8, 4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIN5jSppm4yC"
      },
      "source": [
        "The basic rule about reshaping the tensor is definitely that you cannot change the total number of elements in it, so the product of all tensor's dimensions should always be the same. It gives us the ability to avoid specifying one dimension when reshaping the tensor - Pytorch can calculate it for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3D19ERFmzOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b49f6393-7a79-4da7-bb31-b5d8cd885e3a"
      },
      "source": [
        "print(tensor.reshape(3, 2, 4).shape)\n",
        "print(tensor.reshape(3, 2, -1).shape)\n",
        "print(tensor.reshape(3, -1, 4).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObgCQKUiETak"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Question 9:\n",
        "\n",
        "Consider a tensor `a` created with [1, 2, 3] and [1, 2, 3] of size (2, 3) is reshaped with operation `.reshape(-1, 2)`. Also consider a tensor `b` created with [[2, 1]] and of size (1, 2), later operated with `view(2, -1)` operation. \n",
        "\n",
        "If we do a dot product of a and b (using `torch.mm`) and perform the sum of all the elements (using `torch.sum`) what do we get? (enter int value without any decimal point in the quiz)\n",
        "<hr>\n",
        "18\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldzV2Uc0J4Aa",
        "outputId": "4c9d93d6-b174-496f-9939-e3b499cf289b"
      },
      "source": [
        "a = torch.tensor([[1,2,3], [1,2,3]])\n",
        "print (a)\n",
        "a = a.reshape(-1,2)\n",
        "print (a)\n",
        "\n",
        "\n",
        "b = torch.tensor([[2,1]])\n",
        "print (b)\n",
        "b = b.view(2,-1)\n",
        "print (b)\n",
        "\n",
        "prod = torch.mm(a,b)\n",
        "print (prod)\n",
        "\n",
        "torch.sum(prod)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "tensor([[1, 2],\n",
            "        [3, 1],\n",
            "        [2, 3]])\n",
            "tensor([[2, 1]])\n",
            "tensor([[2],\n",
            "        [1]])\n",
            "tensor([[4],\n",
            "        [7],\n",
            "        [7]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mza7QPg3ndeV"
      },
      "source": [
        "**Alternative ways to view tensors** - `expand` or `expand_as`.\n",
        "\n",
        "\n",
        "\n",
        "*   `expand` - requires the desired shape as an input\n",
        "*   `expand_as` - uses the shape of another tensor\n",
        "\n",
        "These operations \"repeat\" tensor's values along the specified axes without actually copying the data. \n",
        "\n",
        "As the documentation says, expand:\n",
        "\n",
        "\n",
        "> returns a new view of the self tensor with singleton dimensions expanded to a larger size. Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1. \n",
        "\n",
        "**Use case:**\n",
        "\n",
        "\n",
        "\n",
        "*   index multi-channel tensor with single-channel mask - imagine a color image with 3 channels (RGB) and binary mask for the area of interest on that image. We cannot index the image with this kind of mask directly since the dimensions are different, but we can use `expand_as` operation to create a view of the mask that has the same dimensions as the image we want to apply it to, but has not copied the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz33E-V7nPQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "8bcfc71f-b0bb-4c37-e5e0-5c4ffa38aacb"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a black image\n",
        "image = torch.zeros(size=(3, 256, 256), dtype=torch.int)\n",
        "\n",
        "# Leave the borders and make the rest of the image Green\n",
        "image[1, 18:256 - 18, 18:256 - 18] = 255\n",
        "\n",
        "# Create a mask of the same size\n",
        "mask = torch.zeros(size=(256, 256), dtype=torch.bool)\n",
        "\n",
        "# Assuming the green region in the original image is the Region of interest, change the mask to white for that area\n",
        "mask[18:256 - 18, 18:256 - 18] = 1\n",
        "\n",
        "# Create a view of the mask with the same dimensions as the original image\n",
        "mask_expanded = mask.expand_as(image)\n",
        "print(mask_expanded.shape)\n",
        "\n",
        "mask_np = mask_expanded.numpy().transpose(1, 2, 0) * 255\n",
        "image_np = image.numpy().transpose(1, 2, 0)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[0, mask] += 128\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[mask_expanded] += 128\n",
        "image.clamp_(0, 255)\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiXBx0k3ptOI"
      },
      "source": [
        "In the example above, one can also find a couple of useful tricks:\n",
        "\n",
        "\n",
        "*   `clamp` method and function is a Pytorch's analogue of NumPy's `clip` function\n",
        "*   many operations on tensors have in-place form, that does not return modified data, but change values in the tensor. The in-place version of the operation has trailing underscore according to Pytorch's naming convension - in the exmaple above it is `clamp_`\n",
        "*   tensors have the same indexing as Numpy's arrays - one can use `:` seperated range, negative indexes and so on.\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Images and their representations\n",
        "\n",
        "Now, let's discuss images, their representations and how different Python librarties work with them. \n",
        "\n",
        "Probably, the most well-known library for image loading and simple processing is [Pillow](https://pillow.readthedocs.io/en/stable/). \n",
        "\n",
        "However, many people in deep learning area stick with OpenCV for image loading and processing with some usage of another libraries when it is justified by performance/functionality. This is because OpenCV is in general much faster than the other libraries. Here you can find a couple of benchmarks: \n",
        "\n",
        "*   https://www.kaggle.com/zfturbo/benchmark-2019-speed-of-image-reading\n",
        "*   https://github.com/albumentations-team/albumentations#benchmarking-results\n",
        "\n",
        "To sum up the benchmarks above, there are two most common image formats, PNG and JPEGs. If your data is in PNG format - use OpenCV to read it. If it is in JPEG - use libturbojpeg. For image processing, use OpenCV if possible. _We will be using PIL a lot along with these._\n",
        "\n",
        "As you will read the code from others, you may find out that some of them use Pillow/something else to read data. You should know, that color image representations in OpenCV and other libraries are different - OpenCV uses \"BGR\" channel order, while others use \"RGB\" one. \n",
        "\n",
        "To change \"BRG\" <-> \"RGB\" the only thing we need to do it to change channel order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrBM9FNhOn1f",
        "outputId": "6535d422-a108-48b8-d5e9-d92cadfcebec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9uihzWPTfW",
        "outputId": "919b9f7d-4d59-48c3-9c87-55060113e49b"
      },
      "source": [
        "!ls \"/content/drive/My Drive/EVA7\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVA7_S2_Assignment.ipynb  mars.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYv4sZMmpndu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "68b03576-fabf-4a75-d13b-258bfda8683a"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "bgr_image = cv2.imread('/content/drive/My Drive/EVA7/mars.jpg') \n",
        "# remember to add your own image in case you run this block, if you want to use the same image, \n",
        "# download it from: https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRCA40ftnscVzfV8ft8e7vIzQXfXeZdtco8nknJrfCUW6INI40U\n",
        "rgb_image = bgr_image[..., ::-1]\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(bgr_image)\n",
        "ax[1].imshow(rgb_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoi4TeNBGHle"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 10:\n",
        "\n",
        "Looking at the results above it can be said that the pixel values in the blue channels would be very small compared to red channel. True/False?\n",
        "<hr>\n",
        "True\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ugFd57zNwa"
      },
      "source": [
        "# Autograd\n",
        "\n",
        "Pytorch supports automatic differentiation. The module which implements this is called **AutoGrad**. It calculates the gradients and keeps track in forward and backward passes. For primitive tensors, you need to enable or disable it using the `required_grad` flag. But, for advanced tensors, it is enabled by default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMOp4aiou6JR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e9a22acd-21b1-427d-c1c0-90302bc1c37a"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad = True)\n",
        "print(a)\n",
        "result = a * 5\n",
        "print(result)\n",
        "\n",
        "# grad can be implicitly created only for scalar outputs\n",
        "# so let's calculate the sum here so that the output becomes a scalar and we can apply a backward pass\n",
        "mean_result = result.sum()\n",
        "print(mean_result)\n",
        "# calculate gradient\n",
        "mean_result.backward()\n",
        "# print gradient of a\n",
        "print(a.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1420, 0.0529, 0.6277, 0.6623, 0.4401],\n",
            "        [0.0893, 0.8400, 0.5712, 0.4038, 0.1173],\n",
            "        [0.3958, 0.8571, 0.1979, 0.5202, 0.4367]], requires_grad=True)\n",
            "tensor([[0.7102, 0.2647, 3.1385, 3.3117, 2.2004],\n",
            "        [0.4464, 4.2000, 2.8562, 2.0192, 0.5864],\n",
            "        [1.9788, 4.2853, 0.9895, 2.6009, 2.1835]], grad_fn=<MulBackward0>)\n",
            "tensor(31.7716, grad_fn=<SumBackward0>)\n",
            "tensor([[5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym0Amk2IGfLx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 11: \n",
        "\n",
        "Why the gradient of a is all 5s above?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PDgGq2R0k7I"
      },
      "source": [
        "As we see, Pytorch automagically calculated the gradient value for us. It looks to be the correct value - we multiplied an input by 5, so the gradient of this operation equals to 5.\n",
        "\n",
        "# Disabling Autograd for tensors\n",
        "\n",
        "We don't need to compute gradients for all the variables that are involved in the pipeline. The Pytorch API provides 2 ways to disable autograd.\n",
        "\n",
        "`detach` - returns a copy of the tensor with autograd disabled. This \n",
        "\n",
        "1.   copy is built on the same memory as the original tensor, so in-place size / stride / storage changes (such as resize_ / resizeas / set / transpose) modifications are not allowed.\n",
        "2.   torch.no_grad() - It is a context manager that allows you to guard a series of operations from autograd without creating new tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqVG9fQb0cLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2081f403-31a2-4296-c670-b899e246a8cc"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad=True)\n",
        "detached_a = a.detach()\n",
        "detached_result = detached_a * 5\n",
        "result = a * 10\n",
        "# we cannot do backward pass that is required for autograd using multideminsional output,\n",
        "# so let's calculate the sum here\n",
        "mean_result = result.sum()\n",
        "mean_result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqpch2Be02J7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0a5ee8e8-81b8-46f0-c7fc-ac406657e928"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    detached_result = a * 5\n",
        "result = a * 10\n",
        "# we cannot do backward pass that is required for autograd using multideminsional output,\n",
        "# so let's calculate the sum here\n",
        "mean_result = result.sum()\n",
        "mean_result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjh2rYOPJUAZ"
      },
      "source": [
        "# Custom Network\n",
        "\n",
        "A fully-connected ReLU network with one hidden layer and no biases, trained to predict y from x by minimizing squared Euclidean distance.\n",
        "\n",
        "This implementation uses PyTorch tensors to manually compute the forward pass, loss, and backward pass.\n",
        "\n",
        "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
        "\n",
        "The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU, just cast the Tensor to a cuda datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nf5RaB104Vp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb185bc-92b4-4aba-8798-256b9072bbdf"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0)\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2*(y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 27728448.0\n",
            "1 26851886.0\n",
            "2 31172524.0\n",
            "3 36286980.0\n",
            "4 36372524.0\n",
            "5 28601648.0\n",
            "6 16980198.0\n",
            "7 8279489.5\n",
            "8 3880792.0\n",
            "9 2069765.25\n",
            "10 1330616.625\n",
            "11 991062.25\n",
            "12 801250.1875\n",
            "13 674125.625\n",
            "14 578160.125\n",
            "15 501035.8125\n",
            "16 437209.9375\n",
            "17 383423.4375\n",
            "18 337697.09375\n",
            "19 298550.53125\n",
            "20 264834.875\n",
            "21 235659.546875\n",
            "22 210294.203125\n",
            "23 188154.1875\n",
            "24 168771.625\n",
            "25 151756.546875\n",
            "26 136750.5625\n",
            "27 123472.6484375\n",
            "28 111716.3671875\n",
            "29 101270.984375\n",
            "30 91965.1875\n",
            "31 83664.9609375\n",
            "32 76233.6484375\n",
            "33 69558.390625\n",
            "34 63538.16796875\n",
            "35 58115.40234375\n",
            "36 53218.375\n",
            "37 48790.2421875\n",
            "38 44779.75390625\n",
            "39 41143.5\n",
            "40 37842.6796875\n",
            "41 34841.7890625\n",
            "42 32107.2265625\n",
            "43 29613.904296875\n",
            "44 27337.7890625\n",
            "45 25257.60546875\n",
            "46 23353.888671875\n",
            "47 21611.3828125\n",
            "48 20013.12890625\n",
            "49 18550.5234375\n",
            "50 17206.03515625\n",
            "51 15969.76953125\n",
            "52 14831.78125\n",
            "53 13784.0791015625\n",
            "54 12816.9150390625\n",
            "55 11924.349609375\n",
            "56 11099.9013671875\n",
            "57 10338.0673828125\n",
            "58 9633.4765625\n",
            "59 8981.48046875\n",
            "60 8377.1591796875\n",
            "61 7817.19677734375\n",
            "62 7298.24267578125\n",
            "63 6816.57666015625\n",
            "64 6369.7392578125\n",
            "65 5954.61279296875\n",
            "66 5568.42431640625\n",
            "67 5209.2001953125\n",
            "68 4875.0400390625\n",
            "69 4563.931640625\n",
            "70 4274.3759765625\n",
            "71 4004.597412109375\n",
            "72 3753.05615234375\n",
            "73 3518.473388671875\n",
            "74 3299.537109375\n",
            "75 3095.169189453125\n",
            "76 2904.515625\n",
            "77 2726.51611328125\n",
            "78 2560.1435546875\n",
            "79 2404.538818359375\n",
            "80 2258.98779296875\n",
            "81 2122.904541015625\n",
            "82 1995.5498046875\n",
            "83 1876.21875\n",
            "84 1764.49560546875\n",
            "85 1659.816650390625\n",
            "86 1561.7169189453125\n",
            "87 1469.7655029296875\n",
            "88 1383.4708251953125\n",
            "89 1302.53125\n",
            "90 1226.6134033203125\n",
            "91 1155.3570556640625\n",
            "92 1088.503662109375\n",
            "93 1025.678466796875\n",
            "94 966.6693115234375\n",
            "95 911.2400512695312\n",
            "96 859.14599609375\n",
            "97 810.2122802734375\n",
            "98 764.1893310546875\n",
            "99 720.8975219726562\n",
            "100 680.1775512695312\n",
            "101 641.8634643554688\n",
            "102 605.818603515625\n",
            "103 571.9000244140625\n",
            "104 539.9489135742188\n",
            "105 509.864013671875\n",
            "106 481.5389709472656\n",
            "107 454.8831787109375\n",
            "108 429.7464294433594\n",
            "109 406.0559997558594\n",
            "110 383.73504638671875\n",
            "111 362.7198791503906\n",
            "112 342.89031982421875\n",
            "113 324.1952209472656\n",
            "114 306.5760192871094\n",
            "115 289.9417419433594\n",
            "116 274.2464599609375\n",
            "117 259.4280700683594\n",
            "118 245.44850158691406\n",
            "119 232.24742126464844\n",
            "120 219.79490661621094\n",
            "121 208.02366638183594\n",
            "122 196.90878295898438\n",
            "123 186.4141387939453\n",
            "124 176.5067901611328\n",
            "125 167.1317901611328\n",
            "126 158.27342224121094\n",
            "127 149.9081573486328\n",
            "128 142.00311279296875\n",
            "129 134.52638244628906\n",
            "130 127.45906066894531\n",
            "131 120.76878356933594\n",
            "132 114.45063781738281\n",
            "133 108.4666748046875\n",
            "134 102.81217193603516\n",
            "135 97.45960998535156\n",
            "136 92.39663696289062\n",
            "137 87.60406494140625\n",
            "138 83.06949615478516\n",
            "139 78.7743148803711\n",
            "140 74.71261596679688\n",
            "141 70.86373138427734\n",
            "142 67.21857452392578\n",
            "143 63.76879119873047\n",
            "144 60.50208282470703\n",
            "145 57.40964889526367\n",
            "146 54.47645568847656\n",
            "147 51.70027160644531\n",
            "148 49.06986618041992\n",
            "149 46.57585525512695\n",
            "150 44.213008880615234\n",
            "151 41.973724365234375\n",
            "152 39.85015869140625\n",
            "153 37.83811950683594\n",
            "154 35.92998504638672\n",
            "155 34.12189865112305\n",
            "156 32.40614700317383\n",
            "157 30.779396057128906\n",
            "158 29.23752212524414\n",
            "159 27.775245666503906\n",
            "160 26.387603759765625\n",
            "161 25.071128845214844\n",
            "162 23.822494506835938\n",
            "163 22.63796615600586\n",
            "164 21.51299285888672\n",
            "165 20.445938110351562\n",
            "166 19.43364906311035\n",
            "167 18.471542358398438\n",
            "168 17.559720993041992\n",
            "169 16.693696975708008\n",
            "170 15.871532440185547\n",
            "171 15.090553283691406\n",
            "172 14.349206924438477\n",
            "173 13.645315170288086\n",
            "174 12.977251052856445\n",
            "175 12.342586517333984\n",
            "176 11.739442825317383\n",
            "177 11.166200637817383\n",
            "178 10.622243881225586\n",
            "179 10.105524063110352\n",
            "180 9.614072799682617\n",
            "181 9.147530555725098\n",
            "182 8.704154968261719\n",
            "183 8.282634735107422\n",
            "184 7.881793022155762\n",
            "185 7.501204967498779\n",
            "186 7.139141082763672\n",
            "187 6.795079708099365\n",
            "188 6.468428134918213\n",
            "189 6.157524585723877\n",
            "190 5.862307071685791\n",
            "191 5.581362724304199\n",
            "192 5.314339637756348\n",
            "193 5.060612678527832\n",
            "194 4.8191022872924805\n",
            "195 4.58932638168335\n",
            "196 4.370878219604492\n",
            "197 4.1630120277404785\n",
            "198 3.965399742126465\n",
            "199 3.7770230770111084\n",
            "200 3.5980048179626465\n",
            "201 3.4276249408721924\n",
            "202 3.265580415725708\n",
            "203 3.111335039138794\n",
            "204 2.96492862701416\n",
            "205 2.824864149093628\n",
            "206 2.6920394897460938\n",
            "207 2.5653116703033447\n",
            "208 2.444700002670288\n",
            "209 2.3299288749694824\n",
            "210 2.221003293991089\n",
            "211 2.1169230937957764\n",
            "212 2.017775535583496\n",
            "213 1.9236528873443604\n",
            "214 1.833672285079956\n",
            "215 1.7482695579528809\n",
            "216 1.6667349338531494\n",
            "217 1.5893385410308838\n",
            "218 1.5155125856399536\n",
            "219 1.4449896812438965\n",
            "220 1.3778220415115356\n",
            "221 1.3141487836837769\n",
            "222 1.2532590627670288\n",
            "223 1.1952228546142578\n",
            "224 1.1401762962341309\n",
            "225 1.087509036064148\n",
            "226 1.0373703241348267\n",
            "227 0.9895204305648804\n",
            "228 0.944004237651825\n",
            "229 0.900579035282135\n",
            "230 0.8592406511306763\n",
            "231 0.8198118805885315\n",
            "232 0.7821362614631653\n",
            "233 0.7463361024856567\n",
            "234 0.712203323841095\n",
            "235 0.6795650720596313\n",
            "236 0.6485363245010376\n",
            "237 0.6188957095146179\n",
            "238 0.5907467603683472\n",
            "239 0.5638116002082825\n",
            "240 0.538219690322876\n",
            "241 0.513666033744812\n",
            "242 0.49035710096359253\n",
            "243 0.4681389033794403\n",
            "244 0.4469059705734253\n",
            "245 0.42663419246673584\n",
            "246 0.40731126070022583\n",
            "247 0.38885214924812317\n",
            "248 0.37125033140182495\n",
            "249 0.3545100688934326\n",
            "250 0.3385311961174011\n",
            "251 0.32326555252075195\n",
            "252 0.30865347385406494\n",
            "253 0.29474136233329773\n",
            "254 0.28147703409194946\n",
            "255 0.2688343822956085\n",
            "256 0.25671011209487915\n",
            "257 0.24519704282283783\n",
            "258 0.23423777520656586\n",
            "259 0.22372063994407654\n",
            "260 0.2137628048658371\n",
            "261 0.20421963930130005\n",
            "262 0.1950826644897461\n",
            "263 0.18636535108089447\n",
            "264 0.178039088845253\n",
            "265 0.17003051936626434\n",
            "266 0.16249941289424896\n",
            "267 0.1552153378725052\n",
            "268 0.14832179248332977\n",
            "269 0.14175060391426086\n",
            "270 0.1354498267173767\n",
            "271 0.1294623166322708\n",
            "272 0.12371903657913208\n",
            "273 0.11823859065771103\n",
            "274 0.11296737939119339\n",
            "275 0.10796457529067993\n",
            "276 0.10320034623146057\n",
            "277 0.09864449501037598\n",
            "278 0.09426471590995789\n",
            "279 0.09009494632482529\n",
            "280 0.0861305370926857\n",
            "281 0.08234462141990662\n",
            "282 0.07873302698135376\n",
            "283 0.07526884227991104\n",
            "284 0.0719662755727768\n",
            "285 0.06879415363073349\n",
            "286 0.06578748673200607\n",
            "287 0.06289838999509811\n",
            "288 0.060137636959552765\n",
            "289 0.05751925706863403\n",
            "290 0.05497864633798599\n",
            "291 0.05257504805922508\n",
            "292 0.0502731092274189\n",
            "293 0.04807554557919502\n",
            "294 0.04597512632608414\n",
            "295 0.04397445172071457\n",
            "296 0.04205066338181496\n",
            "297 0.040221527218818665\n",
            "298 0.03848050907254219\n",
            "299 0.0368172749876976\n",
            "300 0.03522449731826782\n",
            "301 0.03369438275694847\n",
            "302 0.03223556652665138\n",
            "303 0.030844932422041893\n",
            "304 0.029509669169783592\n",
            "305 0.028237367048859596\n",
            "306 0.027010470628738403\n",
            "307 0.025843024253845215\n",
            "308 0.024723965674638748\n",
            "309 0.0236660223454237\n",
            "310 0.02263561636209488\n",
            "311 0.021666184067726135\n",
            "312 0.020735759288072586\n",
            "313 0.019844558089971542\n",
            "314 0.019008591771125793\n",
            "315 0.01819881796836853\n",
            "316 0.017422882840037346\n",
            "317 0.016683852300047874\n",
            "318 0.01597519963979721\n",
            "319 0.015286463312804699\n",
            "320 0.014639964327216148\n",
            "321 0.014015540480613708\n",
            "322 0.013421873562037945\n",
            "323 0.012860097922384739\n",
            "324 0.0123165063560009\n",
            "325 0.011793551966547966\n",
            "326 0.011299753561615944\n",
            "327 0.010826573707163334\n",
            "328 0.010380927473306656\n",
            "329 0.009943747892975807\n",
            "330 0.009522596374154091\n",
            "331 0.009127965196967125\n",
            "332 0.0087536396458745\n",
            "333 0.00838862732052803\n",
            "334 0.008040845394134521\n",
            "335 0.007712835446000099\n",
            "336 0.0073980786837637424\n",
            "337 0.0070911976508796215\n",
            "338 0.006801958661526442\n",
            "339 0.006526436656713486\n",
            "340 0.006262088660150766\n",
            "341 0.006005661562085152\n",
            "342 0.00576331140473485\n",
            "343 0.005532946437597275\n",
            "344 0.0053100879304111\n",
            "345 0.0051005263812839985\n",
            "346 0.004899794235825539\n",
            "347 0.0047056423500180244\n",
            "348 0.004519036505371332\n",
            "349 0.004341467749327421\n",
            "350 0.004171848297119141\n",
            "351 0.004008457530289888\n",
            "352 0.0038505198899656534\n",
            "353 0.003704177215695381\n",
            "354 0.0035625267773866653\n",
            "355 0.0034270514734089375\n",
            "356 0.00329283787868917\n",
            "357 0.0031693943310528994\n",
            "358 0.0030477396212518215\n",
            "359 0.0029340877663344145\n",
            "360 0.0028262552805244923\n",
            "361 0.002722471719607711\n",
            "362 0.002621745690703392\n",
            "363 0.0025233214255422354\n",
            "364 0.002430401975288987\n",
            "365 0.0023437119089066982\n",
            "366 0.00226022582501173\n",
            "367 0.0021783330012112856\n",
            "368 0.0021021077409386635\n",
            "369 0.0020295665599405766\n",
            "370 0.0019575569313019514\n",
            "371 0.0018892319640144706\n",
            "372 0.0018231561407446861\n",
            "373 0.0017584770685061812\n",
            "374 0.0016985852271318436\n",
            "375 0.0016385877970606089\n",
            "376 0.001583414850756526\n",
            "377 0.001530685811303556\n",
            "378 0.0014789163833484054\n",
            "379 0.0014271883992478251\n",
            "380 0.0013798139989376068\n",
            "381 0.0013350730296224356\n",
            "382 0.001291767111979425\n",
            "383 0.001249475753866136\n",
            "384 0.0012090771924704313\n",
            "385 0.001169723691418767\n",
            "386 0.0011341135250404477\n",
            "387 0.0010954574681818485\n",
            "388 0.0010605102870613337\n",
            "389 0.0010283978190273046\n",
            "390 0.0009965358767658472\n",
            "391 0.0009670372237451375\n",
            "392 0.0009375557419843972\n",
            "393 0.0009092048276215792\n",
            "394 0.000880989246070385\n",
            "395 0.0008547877077944577\n",
            "396 0.0008287242380902171\n",
            "397 0.0008035325445234776\n",
            "398 0.0007810269016772509\n",
            "399 0.0007574478513561189\n",
            "400 0.0007359609589911997\n",
            "401 0.0007145411800593138\n",
            "402 0.0006941507454030216\n",
            "403 0.0006734393537044525\n",
            "404 0.0006540257018059492\n",
            "405 0.0006361179985105991\n",
            "406 0.0006186366081237793\n",
            "407 0.0006004690076224506\n",
            "408 0.0005852305912412703\n",
            "409 0.0005685745854862034\n",
            "410 0.0005525217275135219\n",
            "411 0.0005383245297707617\n",
            "412 0.0005239667952992022\n",
            "413 0.0005104385199956596\n",
            "414 0.0004960091901011765\n",
            "415 0.00048320365021936595\n",
            "416 0.00047109887236729264\n",
            "417 0.00045865244464948773\n",
            "418 0.0004473401349969208\n",
            "419 0.0004355846322141588\n",
            "420 0.00042430756730027497\n",
            "421 0.00041402046917937696\n",
            "422 0.00040325132431462407\n",
            "423 0.00039234652649611235\n",
            "424 0.00038262619636952877\n",
            "425 0.00037299765972420573\n",
            "426 0.00036386260762810707\n",
            "427 0.0003553256392478943\n",
            "428 0.00034639949444681406\n",
            "429 0.0003388544137123972\n",
            "430 0.00033078386331908405\n",
            "431 0.00032281159656122327\n",
            "432 0.00031469465466216207\n",
            "433 0.000307163194520399\n",
            "434 0.00030025059822946787\n",
            "435 0.00029319667373783886\n",
            "436 0.0002860348322428763\n",
            "437 0.000280019041383639\n",
            "438 0.0002739363117143512\n",
            "439 0.0002677080046851188\n",
            "440 0.0002614158729556948\n",
            "441 0.00025558285415172577\n",
            "442 0.0002493124338798225\n",
            "443 0.00024408883473370224\n",
            "444 0.00023910551681183279\n",
            "445 0.00023341909400187433\n",
            "446 0.00022846096544526517\n",
            "447 0.00022353287204168737\n",
            "448 0.00021932562231086195\n",
            "449 0.00021460781863424927\n",
            "450 0.0002109306224156171\n",
            "451 0.00020579977717716247\n",
            "452 0.000201402697712183\n",
            "453 0.0001969734876183793\n",
            "454 0.00019314994278829545\n",
            "455 0.00018980570894200355\n",
            "456 0.0001858034374890849\n",
            "457 0.00018186160014010966\n",
            "458 0.0001779625308699906\n",
            "459 0.00017488101730123162\n",
            "460 0.00017122653662227094\n",
            "461 0.00016808869258966297\n",
            "462 0.0001652091887081042\n",
            "463 0.00016187370056286454\n",
            "464 0.00015874563541729003\n",
            "465 0.0001554270857013762\n",
            "466 0.00015280784282367676\n",
            "467 0.00014989788178354502\n",
            "468 0.00014689353702124208\n",
            "469 0.00014435991761274636\n",
            "470 0.00014134882076177746\n",
            "471 0.00013867496454622597\n",
            "472 0.0001360688329441473\n",
            "473 0.00013369432417675853\n",
            "474 0.00013139797374606133\n",
            "475 0.00012904030154459178\n",
            "476 0.00012727886496577412\n",
            "477 0.00012493497342802584\n",
            "478 0.00012292993778828532\n",
            "479 0.00012036288535455242\n",
            "480 0.00011823200475191697\n",
            "481 0.00011640271259238943\n",
            "482 0.00011426482524257153\n",
            "483 0.00011276907025603577\n",
            "484 0.00011067694140365347\n",
            "485 0.00010886765085160732\n",
            "486 0.00010706179455155507\n",
            "487 0.00010506019316380844\n",
            "488 0.00010324323375243694\n",
            "489 0.00010160516831092536\n",
            "490 9.9995631899219e-05\n",
            "491 9.870795474853367e-05\n",
            "492 9.720797243062407e-05\n",
            "493 9.58090167841874e-05\n",
            "494 9.410200436832383e-05\n",
            "495 9.240605140803382e-05\n",
            "496 9.084045450435951e-05\n",
            "497 8.932295895647258e-05\n",
            "498 8.821023220662028e-05\n",
            "499 8.678618905832991e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycwxAPHZLNST"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Question 12\n",
        "\n",
        "In the code above, why do we have 2 in '2.0*(y_pred - y)`?<hr>\n",
        "Gradient of loss\n",
        "\n",
        "## Question 13\n",
        "In the code above, what does `grad_h[h < 0] = 0` signify?<hr>\n",
        "ReLU function\n",
        "\n",
        "## Question 14\n",
        "In the code above, how many \"epochs\" have we trained the model for? <hr>\n",
        "500\n",
        "\n",
        "## Question 15\n",
        "In the code above, if we take the trained model, and run it on fresh  inputs, the trained model will be able to predict fresh output with high accuracy. <hr>\n",
        "No\n",
        "\n",
        "## Question 16\n",
        "In the code above, if we dont use clone in `grad_h = grad_h_relu.clone()` the model will still train without any issues. <hr>\n",
        "<font color='red'>Model will still run, not clear about how it affects the results</font>"
      ]
    }
  ]
}